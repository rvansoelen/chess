{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gHidden1OutputSize = 20\n",
    "pHidden1OutputSize = 50\n",
    "sHidden1OutputSize = 50\n",
    "hidden2OutputSize = 1\n",
    "seed = 0\n",
    "batchSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MUST GET RANK OF EACH BOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputFile = 'features.pckl'\n",
    "with open(inputFile, 'rb') as fid:\n",
    "    features = pickle.load(fid)\n",
    "    globalFeatures = np.array([feature['globalFeatures'] for feature in features], dtype='float32')\n",
    "    pieceFeatures  = np.array([feature['pieceFeatures'] for feature in features], dtype='float32')\n",
    "    squareFeatures = np.array([feature['squareFeatures'] for feature in features], dtype='float32')\n",
    "    ranks = np.array([feature['moveRankings'] for feature in features], dtype='float32')\n",
    "    labels = np.array([feature['labels'] for feature in features], dtype='float32')\n",
    "\n",
    "    globalLength= globalFeatures.shape[1]\n",
    "    pieceLength = pieceFeatures.shape[1]\n",
    "    squareLength = squareFeatures.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pieceFeatures', 'labels', 'squareFeatures', 'moveRankings', 'globalFeatures']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "globalTensor = tf.convert_to_tensor(globalFeatures, dtype=tf.float32)\n",
    "pieceTensor = tf.convert_to_tensor(pieceFeatures, dtype=tf.float32)\n",
    "squareTensor = tf.convert_to_tensor(squareFeatures, dtype=tf.float32)\n",
    "rankTensor = tf.convert_to_tensor(ranks, dtype=tf.float32)\n",
    "labelTensor = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "train_input_queue = tf.train.slice_input_producer(\n",
    "                                    [globalFeatures, \n",
    "                                     pieceFeatures, \n",
    "                                     squareFeatures,\n",
    "                                     ranks,\n",
    "                                     labels],\n",
    "                                    shuffle=False)\n",
    "\n",
    "globalBatch, pieceBatch, squareBatch, rankBatch, labelBatch = tf.train.batch(\n",
    "                                    train_input_queue,\n",
    "                                    batch_size=batchSize\n",
    "                                    #,num_threads=1\n",
    "                                    )\n",
    "\n",
    "#global variables\n",
    "with tf.variable_scope('GlobalVariables'):\n",
    "   # globalFeats = tf.placeholder(tf.float32, shape=(batchSize, globalLength), name='GlobalFeatures')#1 bit (everything is really just floats)\n",
    "    #global hidden layer\n",
    "    gHidden1 = tf.layers.dense(globalBatch, gHidden1OutputSize, name='GlobalHiddenLayer1', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(seed=seed))\n",
    "    #testWeights = tf.get_variable(\"kernel\")\n",
    "#piece-centric variables\n",
    "with tf.variable_scope('Piece-CentricVariables'):\n",
    "    #pieceFeats = tf.placeholder(tf.float32, shape=(batchSize, pieceLength), name='Piece-CentricFeatures')\n",
    "\n",
    "    #piece-centric hidden layer\n",
    "    pHidden1 = tf.layers.dense(pieceBatch, pHidden1OutputSize, name='Piece-CentricHiddenLayer1', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(seed=seed))\n",
    "\n",
    "#square-centric variables\n",
    "with tf.variable_scope('Sqaure-CentricVariables'):\n",
    "    #squareFeats = tf.placeholder(tf.float32, shape=(batchSize, squareLength), name='Square-CentricFeatures')\n",
    "    squareRankBatch = tf.concat([squareBatch, rankBatch], 1)\n",
    "    #square-centric hidden layer\n",
    "    sHidden1 = tf.layers.dense(squareRankBatch, sHidden1OutputSize, name='Square-CentricHiddenLayer1', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(seed=seed))\n",
    "\n",
    "input2 = tf.concat([gHidden1, pHidden1, sHidden1], 1)\n",
    "logits = tf.layers.dense(input2, hidden2OutputSize, name='HiddenLayer2', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(seed=seed))\n",
    "probability = tf.nn.sigmoid(logits)\n",
    "loss = tf.losses.sigmoid_cross_entropy(labelBatch, logits) #groundTruth must be of shape [batchSize, 1]\n",
    "optimizer = tf.train.AdadeltaOptimizer()\n",
    "trainer = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 19)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalFeatures.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchesPerEpoch = float(globalFeatures.shape[0])/batchSize\n",
    "numEpochs = 1\n",
    "saveDir = '/home/rvansoelen/rbmcData/savedModels/test/'\n",
    "saveFrequency = 1000\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #print sess.run( weights = tf.get_variable(\"GlobalVariable/kernel\"))\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    lossRecord = []\n",
    "    for i in range(2): #range(int(numEpochs*batchesPerEpoch)):\n",
    "        thisLoss = sess.run((loss, trainer))[0]\n",
    "        lossRecord.append(thisLoss)\n",
    "        if i % saveFrequency == 0:\n",
    "            path = saveDir+'model_'+str(i)+'.ckpt'\n",
    "            save_path = saver.save(sess, path)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    '''tf.saved_model.simple_save(sess,\n",
    "            saveDir,\n",
    "            inputs={'globalFeatures': train_input_queue[0],\n",
    "                    'pieceFeatures': train_input_queue[1], \n",
    "                    'squareFeatures': train_input_queue[2],\n",
    "                    'ranks' : train_input_queue[3], \n",
    "                    'labels' : train_input_queue[4]},\n",
    "            outputs={\"probability\": probability})'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3263891, 1.5419257]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/rvansoelen/rbmcData/savedModels/test/model_0.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    i=0\n",
    "    path = saveDir+'model_'+str(i)+'.ckpt'\n",
    "    saver.restore(sess, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieceFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
